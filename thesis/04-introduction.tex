
\chapter{Introduction} % MN: ja bym sporo zmienił językowo - na dole macie wersje, w ktorej ja troche zmienilem. 

\section{Motivation}

Currently human-computer interaction is based mainly on the use of pointing or typewriter-style devices. 
Those types of interactions are limited and sometimes result in a complicated way of representing a simple operation.
One of the examples is rotating a three-dimensional object.
Using a computer mouse, user needs to grab an object and rotate it using a mouse that can only operate in a two-dimensional screen. 
The operation is counter-intuitive and all users need a few attempts to understand how it is done. 
When dealing with the rotation task in real work, it is simple how to move hands to rotate the object in a wanted way.
Therefore, there exists a need for more natural human-computer interfaces.
One of the proposed approaches utilizes human gestures that are interpreted by the computer.
The most significant gestures are presented by hands.
Utilizing hands as human-computer interface can supported by the fact, that hands are a significant part of non-verbal communication and are also used in the sign language.
The another advantage of hands is the fact, that manipulative tasks performed in real world could be interpreted as gestures and then interpreted by the machine.

The latest technological solutions provide data that can be successfully used to control computer using gestures.
Currently there are several devices that yield data useful for gesture recognition. 
An example of such a controller is Microsoft Kinect.
The Kinect provides a three-dimensional data of the observed scene, but was designed for applications that interpret the whole body of the user. 
That's why, it lacks the needed accuracy for hand gesture recognition
 
Another device that is designed to track the movements of a hand and fingers is a Leap Motion Controller developed by Leap Motion, Inc. introduced in July 2013. 
The Leap Motion as a small device, which can be placed in front of the computer, and it features extreme accuracy up to 0.01 mm. 
The presented controller provides information about a position of each part of the hands detected in the observed space.
The SDK attached to the device allows to recognize three simple pre-defined gestures: circle motion with one finger, swipe action and tapping the virtual keys. 
The data contains information about every detected hand and is transmitted with frequency up 100~Hz. 
The Leap Motion Controller is recognized to provide potential that can be used to develop more natural user interface. 

Currently, no library for gesture recognition supports the Leap Motion Controller and therefore potential user can not define an own database of gestures. 
This is a important limitation when creating LM-based applications.
When developers want to create applications utilizing the gesture recognition, they have to operate on low-level, unprocessed data.
This results in additional work overhead to implement methods for gesture recognition.
Therefore, the goal of this thesis is to develop the library for gesture recognition dedicated to Leap Motion device, which will satisfy the demand for this kind of library and thus help developers to implement applications using gesture human-computer interface.


\section{Objectives}

The main goal of this thesis is to design a library, which allow developers of LM-based applications to easily incorporate gesture recognition into theirs applications.

The objectives of this thesis includes:
\begin{itemize}
\item designing a library architecture, 
\item a comparison of existing methods in the context of a hand gesture recognition,
\item a selection and an implementation of algorithms for the gesture recognition,
\item an implementation of additional modules enabling the recording and reviewing of gestures saved in a format supported by the library,
\item creation of a sample gestures database,
\item performing gesture recognition tests using Leap Motion Controller.
\end{itemize}

In this thesis, machine learning algorithms are used. 
The main recognition modules are based on the Support Vector Machines (SVM) and the Hidden Markov Models (HMM). 
The SVM is a supervised learning algorithm, where the algorithm trains on an input data with known responses, and tries to create a predictor model that generates correct predictions for a new input data.
The HMM is an example of an unsupervised learning algorithm, where model tries to find a hidden structure of data using provided training samples. 

The thesis was developed during the from October 2013 till January 2014.


\section{Thesis organization}
% Wg mnie chapter x powinien byc robiony przez ref, zeby byl odnosnikiem
The thesis is structured in following manner. 
Chapter 1 presents the abstract of this thesis in two language versions --- English and Polish. 
In Chapter 2 presents a motivation, objectives and a scope of this work. 
Chapter 3 contains an overview of the literature concerning the gesture recognition problem. 
In this part descriptions of gestures classifications and known methods used for gesture recognition are provided. 
The presentation of Leap Motion Controller is in Chapter 4. Chapter 5 is devoted to gestures recognizing in the context of Leap Motion Controller.
The Chapter contains also descriptions of gestures classification, data representations and additional processing steps for hand gestures recognition using the Leap Motion device. 
The following Chapter 6 contains proposed methods, evaluation methodology and experiments for static gesture recognition. 
Similarly, Chapter 7 presents a description of dynamic gesture recognition. 
Chapter 8 summarizes the created library --- it's architecture, processes, additional modules, dependencies on other open-source libraries, and an example of it's usage. 
Chapter 9 concludes the thesis and provides a possible future works. 

{\color{red} Michał Nowicki - svm do statycznych, hmm do dynamicznych
Olgierd Pilarczyk - projektowanie architektury, impementacja preprocessingu
Jakub Wąsikowski - visualizer, recorder, rozróżnianie palców, wyznacznie liczby klastrów, klasyfikacja gestów
Katarzyna Zjawin - visualizer, recorder, rozróżnianie palców, klasyfikacja gestów}


