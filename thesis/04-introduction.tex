\chapter{Introduction}

\section{Motivation}

Currently, human-computer interaction is mainly based on the pointing or typewriter-style devices. 
Those types of interactions can limit the user expression and sometimes result in a complicated representation of a simple operation.
One of the overcomplicated control examples is rotating a three-dimensional object.
Using a computer mouse, user needs to grab an object and rotate it using a mouse that can only operate in a two-dimensional screen. 
The rotation operation represented by mouse's movement is counter-intuitive for humans and all users need a few attempts to understand how it is done. 
When dealing with the rotation task in real world, it is simple how to move hands to rotate the object in a wanted way.
Therefore, there exists a need for more natural human-computer interfaces.
One of the proposed approaches utilizes hand gestures that are interpreted by the computer.
Utilizing hands as human-computer interface is supported by the fact, that hands are a significant part of a non-verbal communication and are also used in the sign language.
The another advantage of hands is that manipulative tasks performed using hands in real world could be interpreted as a series of gestures and used as computer input.

The newest sensors provide data that can be successfully used to recognize gestures and therefore control a computer.
Currently, there are several devices that yield a data useful for the gesture recognition. 
An example of such a controller is a Microsoft Kinect.
The Kinect provides a three-dimensional data of the observed scene, but was designed for applications that interpret the movement of the whole body of the user. 
That's why, it lacks the needed accuracy for a hand gesture recognition.
 
Another device that is designed to track the movements of a hand and fingers is a Leap Motion Controller developed by Leap Motion, Inc. introduced in July 2013. 
The Leap Motion is a small device, which can be placed in front of the computer, that features extreme finger detection accuracy up to 0.01 mm. 
The presented controller provides information about a position of each finger and a hand detected in the observed space.
The SDK attached to the device allows to recognize three pre-defined gestures: a circle motion with one finger, a swipe action and tapping on the virtual keys. 
The Leap Motion Controller provides information about every detected hand and is transmitted with frequency up 100~Hz. 
The Leap Motion Controller is commonly recognized as a sensor that can potentially revolutionize the human-computer interactions. 

Currently, there exists no library for gesture recognition that supports the data provided by the Leap Motion Controller.
This is a important limitation when creating Leap Motion-based applications.
Right now, when developers want to create applications utilizing the gesture recognition, they need to operate on low-level, unprocessed data and need to implement the gesture recognition.
The additional work overhead could be minimized using open-source high level library.
Therefore, the goal of this thesis is to develop the library for gesture recognition dedicated to Leap Motion device, which will help developers to implement applications using gestures as a human-computer interface.


\section{Objectives}

The main goal of this thesis is to design a library, which allow developers of LM-based applications to easily incorporate a gesture recognition into theirs applications.

The objectives of this thesis includes:
\begin{itemize}
\item designing a library architecture, 
\item a comparison of existing methods in the context of a hand gesture recognition,
\item a selection and an implementation of algorithms for the gesture recognition,
\item an implementation of additional modules enabling the recording and reviewing of gestures saved in a format supported by the library,
\item creation of a sample gestures database,
\item performing gesture recognition tests using Leap Motion Controller.
\end{itemize}
The additional requirement of the library is that the processing should be realized in real time.

In this thesis, machine learning algorithms are used. 
The main recognition modules are based on the Support Vector Machines (SVM) and the Hidden Markov Models (HMM). 
The SVM is a supervised learning algorithm, where the algorithm trains on an input data with known responses, and tries to create a predictor model that generates correct predictions for a new input data.
The HMM is an example of an unsupervised learning algorithm, where model tries to find a hidden structure of data using provided training samples. 

The thesis was developed during the from October 2013 till January 2014.


\section{Thesis organization}
% Wg mnie chapter x powinien byc robiony przez ref, zeby byl odnosnikiem
The thesis is structured in following manner. 
Chapter 1 presents the abstract of this thesis in two language versions --- English and Polish. 
In Chapter 2 presents a motivation, objectives and a scope of this work. 
Chapter 3 contains an overview of the literature concerning the gesture recognition problem. 
In this part descriptions of gestures classifications and known methods used for gesture recognition are provided. 
The presentation of Leap Motion Controller is in Chapter 4. Chapter 5 is devoted to gestures recognizing in the context of Leap Motion Controller.
The Chapter contains also descriptions of gestures classification, data representations and additional processing steps for hand gestures recognition using the Leap Motion device. 
The following Chapter 6 contains proposed methods, evaluation methodology and experiments for static gesture recognition. 
Similarly, Chapter 7 presents a description of dynamic gesture recognition. 
Chapter 8 summarizes the created library --- it's architecture, processes, additional modules, dependencies on other open-source libraries, and an example of it's usage. 
Chapter 9 concludes the thesis and provides possible future works. 


In this thesis Michał Nowicki described dynamic and static gestures without finger recogniton and confusion matrix. He also implemented code of processing algorithms for static and dynamic gestures recognition without an integration into the library and performed tests evaluating the static and dynamic gesture recognition. Olgierd Pilarczyk has wrote a description of Leap Motion controller, data models, data preprocessing and library architecture. He also made Leap Motion recorder research and implemented preprocessing and integration dynamic gesture module to library. Jakub Wąsikowski wrote the introduction to gesture recognition and described classification of gestures and confusion matrix of static gestures. He also participated in research and invention of gesture classification. He implemented finger recognition, recorder and vizualizer, model and format of gestures recordings, determining the number of clusters for dynamic gestures, class for cross validation, integration static gesture and finger recognition modules to library. Katarzyna Zjawin wrote the introduction, Section regards finger recognition, description of the data model, recognition process, learning process, recorder and visualizer. She also participated in research and invention of gesture classification. She implemented and tested finger recognition, recorder i visualizer, model and format of gestures recordings.


